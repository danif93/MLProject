{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader as load\n",
    "import neural_network as neuronet\n",
    "import activation_functions as af\n",
    "import optimisation_functions as of\n",
    "import cost_functions as cf\n",
    "import learningStep_generators as lg\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters initialization\n",
    "\n",
    "maxEpochs = 50              # the neural net will not train over maxEpochs\n",
    "earlyStopParameter = 5      # number of last error entries the net will take in consideration for early stopping\n",
    "earlyStopThreshold = 0.14   # errors-vector norm threshold for deciding early stop\n",
    "\n",
    "batchSize = 10              # stochastic gradient descent batch size\n",
    "regularParam = 3.0          # lambda\n",
    "hiddenUnit = 20             # neurons number for the single hidden unit layer\n",
    "\n",
    "decayStep = lg.harmonicSeries(3) # at each epoch the step will shrink over the harmonic series\n",
    "constStep = lg.constant(3)       # at each epoch the step will remain constant\n",
    "\n",
    "weightInitErr = 0.3         # if requested, a low delta for weights initialization\n",
    "\n",
    "tr, va, te = load.loadMnist() # train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple execution\n",
    "\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.MeanSquareError)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracy, trainAccuracy, testAccuracy = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant - Decaying step comparison\n",
    "# considerations about oscillating, saturation, early stopping and learning break\n",
    "\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracyC, trainAccuracyC, testAccuracyC = sgdC.SGD(tr, va, te, maxEpochs, batchSize, constStep, earlyStopParameter, earlyStopThreshold)\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork(net=[784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracyD, trainAccuracyD, testAccuracyD = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold)\n",
    "\n",
    "nonZeroConstant = len(np.argwhere(validAccuracyC[0]))\n",
    "nonZeroDecaying = len(np.argwhere(validAccuracyD[0]))\n",
    "\n",
    "plt.title('Constant/Decaying learning step')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([80,100])\n",
    "plt.plot(np.arange(nonZeroConstant),validAccuracyC[0][:nonZeroConstant], label='Costant')\n",
    "plt.plot(nonZeroConstant, testAccuracyC[0], 'x', label='Costant - Test')\n",
    "plt.plot(np.arange(nonZeroDecaying),validAccuracyD[0][:nonZeroDecaying], label='Harmonic Decaying')\n",
    "plt.plot(nonZeroDecaying, testAccuracyD[0], 'x', label='Harmonic Decaying - Test')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy - MSE comparison\n",
    "\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy, weightError=weightInitErr)]\n",
    "sigmoidNetMSE = [neuronet.NeuralNetwork(net=[784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.MeanSquareError, weightError=weightInitErr)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "sgdM = of.StochasticGradientDescent(sigmoidNetMSE)\n",
    "\n",
    "validAccuracyM, trainAccuracyM, testAccuracyM = sgdM.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold)\n",
    "validAccuracyC, trainAccuracyC, testAccuracyC = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold)\n",
    "\n",
    "nonZeroCross = len(np.argwhere(validAccuracyC[0]))\n",
    "nonZeroMSE = len(np.argwhere(validAccuracyM[0]))\n",
    "\n",
    "plt.title('Cross-Entropy / MSE training result')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,100])\n",
    "plt.plot(np.arange(nonZeroCross), validAccuracyC[0][:nonZeroCross], label='Cross-Entropy Validation')\n",
    "plt.plot(nonZeroCross, testAccuracyC[0], 'x', label='Cross-Entropy - Test')\n",
    "plt.plot(np.arange(nonZeroMSE), validAccuracyM[0][:nonZeroMSE], label='MSE')\n",
    "plt.plot(nonZeroMSE, testAccuracyM[0], 'x', label='MSE - Test')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Validation accuracy comparison \n",
    "\n",
    "#SGD(trainingSet, validSet, testSet, numEpochs, batchSize, stepGen, earlyStopParam, earlyStopThrshld, _lambda=0.0, l2Regul=True, trainEval=False)\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracy, trainAccuracy, testAccuracy = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold, trainEval=True)\n",
    "\n",
    "nonZeroValues = len(np.argwhere(validAccuracy[0]))\n",
    "\n",
    "plt.title('Training/Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([80,100])\n",
    "plt.plot(np.arange(nonZeroValues), validAccuracy[0][:nonZeroValues], label='Validation Accuracy')\n",
    "plt.plot(np.arange(nonZeroValues), trainAccuracy[0][:nonZeroValues], label='Train Accuracy')\n",
    "plt.plot(nonZeroValues, testAccuracy[0], 'x', label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Validation accuracy comparison with l2 regularization\n",
    "\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracy, trainAccuracy, testAccuracy = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold, _lambda=regularParam, trainEval=True)\n",
    "\n",
    "nonZeroValues = len(np.argwhere(validAccuracy[0]))\n",
    "\n",
    "plt.title('Training/Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([80,100])\n",
    "plt.plot(np.arange(nonZeroValues), validAccuracy[0][:nonZeroValues], label='Validation Accuracy')\n",
    "plt.plot(np.arange(nonZeroValues), trainAccuracy[0][:nonZeroValues], label='Train Accuracy')\n",
    "plt.plot(nonZeroValues, testAccuracy[0], 'x', label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Test accuracy comparison with l1 regularization\n",
    "\n",
    "sigmoidNetCross = [neuronet.NeuralNetwork([784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)]\n",
    "sgdC = of.StochasticGradientDescent(sigmoidNetCross)\n",
    "validAccuracy, trainAccuracy, testAccuracy = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold, _lambda=regularParam, l2Regul=False, trainEval=True)\n",
    "\n",
    "nonZeroValues = len(np.argwhere(validAccuracy[0]))\n",
    "\n",
    "plt.title('Training/Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([80,100])\n",
    "plt.plot(np.arange(nonZeroValues), validAccuracy[0][:nonZeroValues], label='Validation Accuracy')\n",
    "plt.plot(np.arange(nonZeroValues), trainAccuracy[0][:nonZeroValues], label='Train Accuracy')\n",
    "plt.plot(nonZeroValues, testAccuracy[0], 'x', label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation on hidden unit number\n",
    "\n",
    "nets = [neuronet.NeuralNetwork([784, hiddUnitNumber, 10], unit=af.Sigmoid, cost=cf.CrossEntropy) for hiddUnitNumber in [50,100,150,200]]\n",
    "sgdC = of.StochasticGradientDescent(nets)\n",
    "validAccuracy, trainAccuracy, testAccuracy = sgdC.SGD(tr, va, te, maxEpochs, batchSize, decayStep, earlyStopParameter, earlyStopThreshold, _lambda=regularParam)\n",
    "\n",
    "plt.title('Validation accuracy per hidden unit model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([90,100])\n",
    "for i in np.arange(len(nets)):\n",
    "    nonZeroValues = len(np.argwhere(validAccuracy[i]))\n",
    "    plt.plot(np.arange(nonZeroValues),validAccuracy[i][:nonZeroValues], label='{}'.format(nets[i].net[1:-1]))\n",
    "    plt.plot(nonZeroValues, testAccuracy[i], 'x', label='{} - Test'.format(nets[i].net[1:-1]))    \n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AdaGrad algo - not working\n",
    "\n",
    "sigmoidNetCross = neuronet.NeuralNetwork(net=[784, hiddenUnit, 10], unit=af.Sigmoid, cost=cf.CrossEntropy)\n",
    "agC = of.AdaGrad(sigmoidNetCross)\n",
    "testAccuracy, trainAccuracy = agC.AG(tr, va, te, maxEpochs, batchSize, constStep, _lambda=regularParam, trainEval=True)\n",
    "\n",
    "\n",
    "plt.title('Training/Test accuracy ')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([80,100])\n",
    "plt.plot(np.arange(epochs), testAccuracy, label='Test Accuracy')\n",
    "plt.plot(np.arange(epochs), trainAccuracy, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
